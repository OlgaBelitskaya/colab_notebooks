# -*- coding: utf-8 -*-
"""tfimage_processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10vrmuV2SMc0YDBuwB5_O2WP6C9Umw9ss
"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.display import display,HTML
c1,c2,f1,f2,fs1,fs2=\
'#11ff66','#6611ff','Wallpoet','Orbitron',20,10
def dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):
    display(HTML("""<style>
    @import 'https://fonts.googleapis.com/css?family="""\
    +font+"""&effect=3d-float';</style>
    <h1 class='font-effect-3d-float' 
    style='font-family:"""+font+"""; color:"""+fontcolor+\
    """; font-size:"""+str(fontsize)+"""px;'>
#     %s</h1>"""%string))

dhtml('Code Modules, Setting, & Functions')

import warnings,imageio,urllib
import tensorflow as tf,pylab as pl
import pandas as pd,numpy as np
import tensorflow.keras.layers as tkl
import tensorflow.keras.utils as tku
import tensorflow.keras.callbacks as tkc
import tensorflow_datasets as tfds
from sklearn.metrics import \
classification_report,confusion_matrix
from IPython.core.magic import register_line_magic

warnings.filterwarnings('ignore')
pd.set_option('precision',3)
tf.keras.backend.set_floatx('float64')
tfds.disable_progress_bar()
fpath='https://olgabelitskaya.github.io/'
fn1,fn2='flower.png','cat.png'
fw='weights.best.hdf5'
buffer_size,batch_size=500,128
pixels,pixels2=64,128
num_classes=5

def show2(img1,img2):
    pl.subplot(1,2,1); pl.imshow(img1)
    pl.subplot(1,2,2); pl.imshow(img2)
    pl.show()
def preprocess(item,img_size):
    img,lbl=item['image'],item['label']
    img_cropped=tf.image.central_crop(img,.95)
    img_resized=tf.image.resize(
        img_cropped,size=(img_size,img_size))
    img_flip=tf.image\
    .random_flip_left_right(img_resized)
    return (img_flip/255.,tf.cast(lbl,tf.int32))
@register_line_magic
def display_examples(pars):
    pars=pars.split()
    data,n=pars[0],int(pars[1])
    if data=='cats_vs_dogs': data=cvd_test
    if data=='tf_flowers': data=flower_test
    batch=next(iter(data.batch(n)))
    images=batch[0].numpy()
    labels=batch[1].numpy() 
    fig=pl.figure(figsize=(2*n//3,4.5))
    for i in range(n):
        ax=fig.add_subplot(3,n//3,i+1)
        ax.set_xticks([]); ax.set_yticks([])
        ax.imshow(images[i])
        ax.text(.85,.15,'{}'.format(labels[i]), 
                fontdict={'color':c1,'fontsize':30},
                horizontalalignment='center',
                verticalalignment='center', 
                transform=ax.transAxes)
    pl.show()

@register_line_magic
def history_plot(yes):
    global history
    pl.figure(figsize=(10,10)); pl.subplot(211)
    keys=list(history.history.keys())[0:4]
    pl.plot(history.history[keys[0]],
            color=c1,label='train')
    pl.plot(history.history[keys[2]],
            color=c2,label='valid')
    pl.xlabel("Epochs"); pl.ylabel("Loss")
    pl.legend(); pl.grid()
    pl.title('Loss Function')     
    pl.subplot(212)
    pl.plot(history.history[keys[1]],
            color=c1,label='train')
    pl.plot(history.history[keys[3]],
            color=c2,label='valid')
    pl.xlabel("Epochs"); pl.ylabel("Accuracy")    
    pl.legend(); pl.grid()
    pl.title('Accuracy'); pl.show()
def cb(fw):
    early_stopping=\
    tkc.EarlyStopping(monitor='val_loss',
                      patience=20,verbose=2)
    checkpointer=\
    tkc.ModelCheckpoint(filepath=fw,
                        save_best_only=True,verbose=2)
    lr_reduction=\
    tkc.ReduceLROnPlateau(monitor='val_loss',verbose=2,
                          patience=5,factor=.75)
    return [checkpointer,early_stopping,
            lr_reduction]

@register_line_magic
def display_reports(d):
    global model,fw,buffer_size,c2,f2,fs2
    model.load_weights(fw)
    if d=='cats_vs_dogs': data=cvd_test
    if d=='tf_flowers': data=flower_test
    test_results=model.evaluate(data.batch(buffer_size))
    dhtml('\ntest accuracy: {:.2f}%'\
          .format(test_results[1]*100),
          c2,f2,fs2)
    batch=next(iter(data.batch(buffer_size)))
    y_test=batch[1].numpy()
    py_test=model.predict(data.batch(buffer_size))
    if d=='cats_vs_dogs':
        py_test=tf.sigmoid(py_test)\
                  .numpy().round()
    if d=='tf_flowers':
        py_test=np.argmax(tf.nn.softmax(py_test)\
                            .numpy(),axis=-1)
    py_test=py_test[:buffer_size]
    dhtml('Classification Report',c2,f2,fs2)
    print(classification_report(y_test,py_test))
    dhtml('Confusion Matrix',c2,f2,fs2)
    print(confusion_matrix(y_test,py_test))

dhtml('Image Structure')

input_file=urllib.request.urlopen(fpath+fn1)
output_file=open(fn1,'wb'); 
output_file.write(input_file.read())
output_file.close(); input_file.close()
imgii=imageio.imread(fn1)
imgtf=tf.image.decode_image(tf.io.read_file(fn1))
show2(imgii,imgtf)
pd.DataFrame([[tf.shape(imgii).numpy(),tf.shape(imgtf).numpy()],
              [imgii.dtype,imgtf.dtype],
              [tf.rank(imgii).numpy(),tf.rank(imgtf).numpy()]],
             index=['shape','dtype','rank'],
             columns=['imageio','tensorflow.io'])

dhtml('Image Processing')

def bcrop(img,box):
    return tf.image.crop_to_bounding_box(
        img,box[0],box[1],box[2],box[3])
show2(bcrop(imgii,[0,35,185,205]),
      bcrop(imgtf,[10,35,185,205]))
show2(bcrop(imgii,[0,35,195,205]),
      bcrop(imgtf,[0,25,185,205]))

def ccrop(img,c):
    return tf.image.central_crop(img,c)
show2(ccrop(imgii,.9),ccrop(imgtf,.8))

def hflip(img):
    return tf.image.flip_left_right(img)
def vflip(img):
    return tf.image.flip_up_down(img)
def bright(img,d):
    return tf.image.adjust_brightness(
        img,delta=d)
show2(hflip(imgii),vflip(imgii))
show2(bright(imgii,.1),bright(imgtf,.3))

dhtml('Data Processing')

cvd=tfds.builder('cats_vs_dogs:4.0.0')
cvd.download_and_prepare()
split=['train[:80%]','train[80%:90%]','train[90%:]']
ds=cvd.as_dataset(shuffle_files=False,split=split)
cvd_train=ds[0].map(lambda x: preprocess(x,img_size=pixels))
cvd_valid=ds[1].map(lambda x: preprocess(x,img_size=pixels))
cvd_test=ds[2].map(lambda x: preprocess(x,img_size=pixels))
ncvd_train=int(cvd.info.splits['train[:80%]'].num_examples)
dhtml(str(ncvd_train),c2,f2,fs2)

# Commented out IPython magic to ensure Python compatibility.
dhtml(cvd.info.features['image'],c2,f2,fs2)
dhtml(cvd.info.features['label'],c2,f2,fs2)
# %display_examples cats_vs_dogs 9

cvd_train=cvd_train\
.shuffle(buffer_size=buffer_size).repeat()
cvd_train=cvd_train.batch(batch_size)
cvd_valid=cvd_valid.batch(batch_size)

flower=tfds.builder('tf_flowers')
flower.download_and_prepare()
split=['train[:80%]','train[80%:90%]','train[90%:]']
ds=flower.as_dataset(shuffle_files=False,split=split)
flower_train=ds[0].map(lambda x: preprocess(x,img_size=pixels2))
flower_valid=ds[1].map(lambda x: preprocess(x,img_size=pixels2))
flower_test=ds[2].map(lambda x: preprocess(x,img_size=pixels2))
nflower_train=int(flower.info.splits['train[:80%]'].num_examples)
dhtml(str(nflower_train),c2,f2,fs2)

# Commented out IPython magic to ensure Python compatibility.
dhtml(flower.info.features['image'],c2,f2,fs2)
dhtml(flower.info.features['label'],c2,f2,fs2)
# %display_examples tf_flowers 12

flower_train=flower_train\
.shuffle(buffer_size=buffer_size).repeat()
flower_train=flower_train.batch(batch_size)
flower_valid=flower_valid.batch(batch_size)

dhtml('CNN Binary Classification')

def convb(model,f,ks,d):
    model.add(tkl.Conv2D(
    filters=f,kernel_size=(ks,ks),
    strides=(1,1),padding='same'))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.MaxPool2D(pool_size=(2,2)))
    model.add(tkl.Dropout(d))

model=tf.keras.Sequential()
model.add(tkl.Input((pixels,pixels,3),
                    name='input'))
convb(model,32,5,.2)
convb(model,128,5,.2)
convb(model,512,5,.2)
model.compute_output_shape(
    input_shape=(batch_size,pixels,pixels,3))

model.add(tkl.GlobalAveragePooling2D())   
model.add(tkl.Dense(2048))
model.add(tkl.LeakyReLU(alpha=.02))
model.add(tkl.Dropout(.5))
model.add(tkl.Dense(1,activation=None))
model.compute_output_shape(
    input_shape=(batch_size,pixels,pixels,1))

steps_per_epoch=np.ceil(ncvd_train/batch_size)
model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=tf.keras.losses\
              .BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
history=model.fit(cvd_train,epochs=50,shuffle=True, 
                  validation_data=cvd_valid,
                  callbacks=cb(fw),
                  steps_per_epoch=steps_per_epoch)

# Commented out IPython magic to ensure Python compatibility.
# %history_plot yes

# Commented out IPython magic to ensure Python compatibility.
# %display_reports cats_vs_dogs

dhtml('CNN Classification')

model=tf.keras.Sequential()
model.add(tkl.Input((pixels2,pixels2,3),
                    name='input'))
convb(model,32,5,.2)
convb(model,64,5,.2)
convb(model,128,5,.2)
convb(model,256,5,.2)
model.compute_output_shape(
    input_shape=(batch_size,pixels2,pixels2,3))

model.add(tkl.GlobalAveragePooling2D())   
model.add(tkl.Dense(4096))
model.add(tkl.LeakyReLU(alpha=.02))
model.add(tkl.Dropout(.5))
model.add(tkl.Dense(num_classes,activation=None))
model.compute_output_shape(
    input_shape=(batch_size,pixels2,pixels2,3))

steps_per_epoch=np.ceil(nflower_train/batch_size)
model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=tf.keras.losses\
              .SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history=model.fit(flower_train,epochs=50,shuffle=True, 
                  validation_data=flower_valid,
                  callbacks=cb(fw),
                  steps_per_epoch=steps_per_epoch)

# Commented out IPython magic to ensure Python compatibility.
# %history_plot yes

# Commented out IPython magic to ensure Python compatibility.
# %display_reports tf_flowers