# -*- coding: utf-8 -*-
"""tensorflow_cookbook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UPT3vUBNdrfHPl33H6FVKRu8Mf-Lc8px
"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.display import display,HTML
def dhtml(str):
    display(HTML("""<style>
    @import url('https://fonts.googleapis.com/css?family=Ewert&effect=3d');      
    </style><h1 class='font-effect-3d' style='font-family:Ewert; color:#ff355e'>
#     %s</h1>"""%str))

dhtml('Code Modules & Helpful Functions')

import warnings; warnings.filterwarnings('ignore')
import numpy as np,pandas as pd,pylab as pl
import tensorflow_hub as th
import zipfile,h5py,urllib
import tensorflow as tf,keras as ks
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint,EarlyStopping
from keras.callbacks import ReduceLROnPlateau
import PIL.Image

fpath='https://olgabelitskaya.github.io/'
hpath='https://tfhub.dev/google/magenta/'+\
      'arbitrary-image-stylization-v1-256/1'
fw1='weights.best.cifar.hdf5'
fw2='weights.best.flowers.hdf5'

def prepro(x_train,y_train,x_test,y_test):
    n=int(len(x_test)/2)
    x_valid,y_valid=x_test[:n],y_test[:n]
    x_test,y_test=x_test[n:],y_test[n:]
    cy_train=ks.utils.to_categorical(y_train,10) 
    cy_valid=ks.utils.to_categorical(y_valid,10)
    cy_test=ks.utils.to_categorical(y_test,10)
    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],
                     [y_train.shape,y_valid.shape,y_test.shape],
                     [cy_train.shape,cy_valid.shape,cy_test.shape]],
                    columns=['train','valid','test'],
                    index=['images','labels','encoded labels'])
    display(df)
    return [[x_train,x_valid,x_test],
            [y_train,y_valid,y_test],
            [cy_train,cy_valid,cy_test]]

def cb(fw):
    early_stopping=tf.keras.callbacks\
    .EarlyStopping(monitor='val_loss',patience=20,verbose=2)
    checkpointer=tf.keras.callbacks\
    .ModelCheckpoint(filepath=fw,save_best_only=True,verbose=2)
    lr_reduction=tf.keras.callbacks\
    .ReduceLROnPlateau(monitor='val_loss',verbose=2,
                       patience=5,factor=.8)
    return [checkpointer,early_stopping,lr_reduction]

def get_img(file):
    input_file=urllib.request.urlopen(fpath+file)
    output_file=open(file,'wb'); 
    output_file.write(input_file.read())
    output_file.close(); input_file.close()
def load_img(path_to_img):
    max_dim=512
    img=tf.io.read_file(path_to_img)
    img=tf.image.decode_image(img,channels=3)
    img=tf.image.convert_image_dtype(img,tf.float32)
    shape=tf.cast(tf.shape(img)[:-1],tf.float32)
    long_dim=max(shape)
    scale=max_dim/long_dim
    new_shape=tf.cast(shape*scale,tf.int32)
    img=tf.image.resize(img,new_shape)
    img=img[tf.newaxis,:]
    return img
def tensor_to_image(tensor):
    tensor=tensor*255
    tensor=np.array(tensor,dtype=np.uint8)
    if np.ndim(tensor)>3:
        assert tensor.shape[0]==1
        tensor=tensor[0]
    return PIL.Image.fromarray(tensor)

dhtml('Data Loading & Preprocessing')

(x_train1,y_train1),(x_test1,y_test1)=\
ks.datasets.cifar10.load_data()
[[x_train1,x_valid1,x_test1],
 [y_train1,y_valid1,y_test1],
 [cy_train1,cy_valid1,cy_test1]]=\
prepro(x_train1,y_train1,x_test1,y_test1)

cifar_labels=['airplane','automobile','bird','cat','deer',
              'dog','frog','horse','ship','truck']
pl.figure(figsize=(2,2)) 
pl.xticks([]); pl.yticks([])
pl.title(cifar_labels[y_train1[200][0]])
pl.imshow(x_train1[200]);

zf='FlowerColorImages.h5.zip'
input_file=urllib.request.urlopen(fpath+zf)
output_file=open(zf,'wb'); 
output_file.write(input_file.read())
output_file.close(); input_file.close()
zipf=zipfile.ZipFile(zf,'r')
zipf.extractall(''); zipf.close()
f=h5py.File(zf[:-4],'r') 
keys=list(f.keys()); keys
images=np.array(f[keys[0]])/255
labels=np.array(f[keys[1]]).astype('int').reshape(-1,1)
x_train2,x_test2,y_train2,y_test2=\
train_test_split(images,labels,test_size=.2,random_state=1)
del images,labels
[[x_train2,x_valid2,x_test2],
 [y_train2,y_valid2,y_test2],
 [cy_train2,cy_valid2,cy_test2]]=\
prepro(x_train2,y_train2,x_test2,y_test2)

flower_labels=['phlox','rose','calendula','iris',
               'max chrysanthemum','bellflower','viola',
               'rudbeckia laciniata','peony','aquilegia']
pl.figure(figsize=(2,2)) 
pl.xticks([]); pl.yticks([])
pl.title(flower_labels[y_train2[150][0]])
pl.imshow(x_train2[150]);

dhtml('Fast Examples')

get_img('picture02.png')
content_image=load_img('picture02.png')
x=tf.keras.applications.vgg19\
.preprocess_input(content_image*255)
x=tf.image.resize(x,(224,224))
vgg19=tf.keras.applications\
.VGG19(include_top=True,weights='imagenet')
prediction_probabilities=vgg19(x)
predicted_top5=tf.keras.applications.vgg19\
.decode_predictions(prediction_probabilities.numpy())[0]
[print((class_name,prob)) 
 for (number,class_name,prob) in predicted_top5]
tensor_to_image(content_image)

hub_module=th.load(hpath)
get_img('picture02.png')
get_img('pattern05.jpeg')
content_image=load_img('picture02.png')
style_image=load_img('pattern05.jpeg')
stylized_image=hub_module(tf.constant(content_image),
                          tf.constant(style_image))[0]
tensor_to_image(stylized_image)

dhtml('Keras Models')

def mlp_model(s):
    model=tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(s,s,3)),
        tf.keras.layers.Dense(128,activation='relu'),
        tf.keras.layers.BatchNormalization(),    
        tf.keras.layers.Dense(256,activation='relu'),
        tf.keras.layers.BatchNormalization(),    
        tf.keras.layers.Dense(512,activation='relu'),
        tf.keras.layers.BatchNormalization(),   
        tf.keras.layers.Dense(1024,activation='relu'),
        tf.keras.layers.Dropout(.2),
        tf.keras.layers.Dense(10,activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

model=mlp_model(32)
model.fit(x_train1,y_train1,epochs=100,
          batch_size=16,callbacks=cb(fw1),
          validation_data=(x_valid1,y_valid1));

model.load_weights(fw1)
model.evaluate(x_test1,y_test1)

model=mlp_model(128)
model.fit(x_train2,y_train2,epochs=100,batch_size=16,
          validation_data=(x_valid2,y_valid2),
          callbacks=cb(fw2))

model.load_weights(fw2)
model.evaluate(x_test2,y_test2)

def cnn_model(s):
    model=tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(32,(5,5),padding='same',
                               input_shape=(s,s,3)),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.Conv2D(196,(5,5)),
        tf.keras.layers.Activation('relu'),    
        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.GlobalAveragePooling2D(),    
        tf.keras.layers.Dense(512),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.Dense(128),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.Dense(10,activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

model=cnn_model(32)
model.fit(x_train1,cy_train1,epochs=100,batch_size=64,
          validation_data=(x_valid1,cy_valid1),
          callbacks=cb(fw1))

model.load_weights(fw1)
model.evaluate(x_test1,cy_test1)

model=cnn_model(128)
model.fit(x_train2,cy_train2,epochs=100,batch_size=64,
          validation_data=(x_valid2,cy_valid2),
          callbacks=cb(fw2))

model.load_weights(fw2)
model.evaluate(x_test2,cy_test2)

def rnn_model(s,h):
    model=tf.keras.models.Sequential([
        tf.keras.layers.BatchNormalization(input_shape=(1,s*s*3)),
        tf.keras.layers.LSTM(h,return_sequences=True), 
        tf.keras.layers.LSTM(h,return_sequences=True),
        tf.keras.layers.LSTM(h),         
        tf.keras.layers.Dense(10,activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy',
                  optimizer='nadam',metrics=['accuracy'])    
    return model

model=rnn_model(32,128)
model.fit(x_train1.reshape(-1,1,32*32*3),cy_train1,
          epochs=50,batch_size=128,
          validation_data=(x_valid1.reshape(-1,1,32*32*3),
                           cy_valid1),
          callbacks=cb(fw1))

model.load_weights(fw1)
model.evaluate(x_test1.reshape(-1,1,32*32*3),cy_test1)

model=rnn_model(128,256)
model.fit(x_train2.reshape(-1,1,128*128*3),cy_train2,
          epochs=50,batch_size=128,
          validation_data=(x_valid2.reshape(-1,1,128*128*3),
                           cy_valid2),
          callbacks=cb(fw2))

model.load_weights(fw2)
model.evaluate(x_test2.reshape(-1,1,128*128*3),cy_test2)