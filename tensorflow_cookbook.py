# -*- coding: utf-8 -*-
"""tensorflow_cookbook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UPT3vUBNdrfHPl33H6FVKRu8Mf-Lc8px
"""

import random; from IPython.display import display,HTML
from IPython.core.magic import register_line_magic
@register_line_magic
def decor_header(params):
    params=params.split('|'); string=params[0]
    if len(params)==1: 
        font_size='24'; font_family='Wallpoet'; cmap='Sinebow'
    elif  len(params)==2: 
        font_size=params[1]
        font_family='Wallpoet'; cmap='Sinebow'
    elif  len(params)==3: 
        font_size=params[1]; font_family=params[2]
        cmap='Sinebow'
    else: 
        font_size=params[1]; font_family=params[2]; cmap=params[3]
    height=max([int(font_size)*2.5,60]) 
    html_str="""
<script src='https://d3js.org/d3.v6.min.js'></script>
<style>
@import 'https://fonts.googleapis.com/css?family="""+font_family+"""';
#colorized001 {
font-family:"""+font_family+"""; font-size:"""+font_size+""";}
#canvas001,#canvas002 {width:10%; vertical-align:middle;}
</style>
<text id='colorized001'><canvas id='canvas001'></canvas>
"""+string+"""
<canvas id='canvas002'></canvas></text><br/>
<script>
var tc=setInterval(function() {
    var now=(new Date().getTime()%5000)/5000;
    var now_slow=(new Date().getTime()%100000)/100000;
    var iddoc=document.getElementById('colorized001');
    iddoc.style.color=d3.interpolate"""+cmap+"""(now);
    var r=10,n=7;
    var c1=document.getElementById('canvas001'); 
    var context1=c1.getContext('2d');
    var c2=document.getElementById('canvas002'); 
    var context2=c2.getContext('2d');
    c1.style.background=d3.interpolate"""+cmap+"""(now_slow); 
    c2.style.background=d3.interpolate"""+cmap+"""(now_slow);
    context1.strokeStyle=d3.interpolate"""+cmap+"""(now);    
    context2.strokeStyle=d3.interpolate"""+cmap+"""(now);
    for (var i=1; i<n; i++) {
        context1.beginPath(); context2.beginPath();
        for (var j=0; j<6; j++) {
            context1.arc(60*j,r*(n+.5),i*r,0,2*Math.PI);
            context2.arc(60*j,r*(n+.5),i*r,0,2*Math.PI); };
        context1.stroke(); context2.stroke(); }; },1)
</script>"""
    display(HTML(html_str))

# Commented out IPython magic to ensure Python compatibility.
# %decor_header Modules, Helpful Functions, & Styling

import warnings; warnings.filterwarnings('ignore')
import numpy as np,pandas as pd,pylab as pl
import tensorflow_hub as th
import seaborn as sn,zipfile,h5py,urllib
import tensorflow as tf,keras as ks
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint,EarlyStopping
from keras.callbacks import ReduceLROnPlateau
import PIL.Image

data_path='https://raw.githubusercontent.com/'+\
          'OlgaBelitskaya/data_kitchen/main/'
file_path='https://olgabelitskaya.gitlab.io/images/'
tfhub_path='https://tfhub.dev/google/magenta/'+\
           'arbitrary-image-stylization-v1-256/1'
model_weights='weights.best.flowers.hdf5'
model_weights2='weights.best.cifar.hdf5'

def prepro(x_train,y_train,x_test,y_test):
    n=int(len(x_test)/2)
    x_valid,y_valid=x_test[:n],y_test[:n]
    x_test,y_test=x_test[n:],y_test[n:]
    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],
                     [y_train.shape,y_valid.shape,y_test.shape]],
                    columns=['train','valid','test'],
                    index=['images','labels'])
    display(df)
    return [[x_train,x_valid,x_test],
            [y_train,y_valid,y_test]]

def cb(fw):
    early_stopping=tf.keras.callbacks\
    .EarlyStopping(monitor='val_loss',patience=20,verbose=2)
    checkpointer=tf.keras.callbacks\
    .ModelCheckpoint(filepath=fw,verbose=int(0),
                     save_weights_only=True,save_best_only=True,
                     monitor='val_accuracy',mode='max')
    lr_reduction=tf.keras.callbacks\
    .ReduceLROnPlateau(monitor='val_loss',verbose=2,
                       patience=5,factor=.8)
    return [checkpointer,early_stopping,lr_reduction]

def load_img(path_to_img):
    max_dim=512
    img=tf.io.read_file(path_to_img)
    img=tf.image.decode_image(img,channels=3)
    img=tf.image.convert_image_dtype(img,tf.float32)
    shape=tf.cast(tf.shape(img)[:-1],tf.float32)
    long_dim=max(shape)
    scale=max_dim/long_dim
    new_shape=tf.cast(shape*scale,tf.int32)
    img=tf.image.resize(img,new_shape)
    img=img[tf.newaxis,:]
    return img
def tensor_to_image(tensor):
    tensor=tensor*255
    tensor=np.array(tensor,dtype=np.uint8)
    if np.ndim(tensor)>3:
        assert tensor.shape[0]==1
        tensor=tensor[0]
    return PIL.Image.fromarray(tensor)

# Commented out IPython magic to ensure Python compatibility.
# %decor_header Data Loading & Preprocessing

zf='Flowers128.h5'
input_file=urllib.request.urlopen(data_path+zf)
output_file=open(zf,'wb')
output_file.write(input_file.read())
output_file.close(); input_file.close()
with h5py.File(zf,'r') as f:
    keys=list(f.keys())
    print('h5py.File keys: '+', '.join(keys))
    images=np.array(f[keys[0]])
    labels=np.array(f[keys[1]])
    names=[el.decode('utf-8')for el in f[keys[2]]]
    f.close()

df=pd.DataFrame(labels,columns=['label'])
df['class']=[names[l] for l in labels]
pl.figure(figsize=(8,4))
sn.countplot(y='class',data=df,palette='cool',alpha=.5)
ti='Label Distribution'
pl.title(ti,fontsize=16); pl.tight_layout(); pl.show()

N=labels.shape[0]; n=int(.1*N); shuffle_ids=np.arange(N)
np.random.RandomState(12).shuffle(shuffle_ids)
images=images[shuffle_ids]; labels=labels[shuffle_ids]
x_test,x_valid,x_train=images[:n],images[n:2*n],images[2*n:]
y_test,y_valid,y_train=labels[:n],labels[n:2*n],labels[2*n:]
df=pd.DataFrame(
    [[x_train.shape,x_valid.shape,x_test.shape],
     [x_train.dtype,x_valid.dtype,x_test.dtype],
     [y_train.shape,y_valid.shape,y_test.shape],
     [y_train.dtype,y_valid.dtype,y_test.dtype]],
    columns=['train','valid','test'],
    index=['image shape','image type','label shape','label type'])
fig=pl.figure(figsize=(8,4)); n=np.random.randint(1,100)
for i in range(n,n+6):
    ax=fig.add_subplot(2,3,i-n+1,xticks=[],yticks=[])
    ax.set_title(
        names[labels[i]],color='slategray',
        fontdict={'fontsize':'large'})
    ax.imshow((images[i]))
pl.tight_layout(); pl.show(); display(df)

(x_train2,y_train2),(x_test2,y_test2)=\
ks.datasets.cifar10.load_data()
[[x_train2,x_valid2,x_test2],
 [y_train2,y_valid2,y_test2]]=\
prepro(x_train2,y_train2,x_test2,y_test2)

cifar_labels=['airplane','automobile','bird','cat','deer',
              'dog','frog','horse','ship','truck']
pl.figure(figsize=(1,1)) 
pl.xticks([]); pl.yticks([])
pl.title(cifar_labels[y_train2[200][0]])
pl.imshow(x_train2[200]);

# Commented out IPython magic to ensure Python compatibility.
# %decor_header Fast Examples

def get_file(file,file_path=file_path):
    input_file=urllib.request.urlopen(file_path+file)
    output_file=open(file,'wb'); 
    output_file.write(input_file.read())
    output_file.close(); input_file.close()
get_file('06_001.png')

content_image=load_img('06_001.png')
x=tf.keras.applications.vgg19\
.preprocess_input(content_image*255)
x=tf.image.resize(x,(224,224))
vgg19=tf.keras.applications\
.VGG19(include_top=True,weights='imagenet')
prediction_probabilities=vgg19(x)
predicted_top5=tf.keras.applications.vgg19\
.decode_predictions(prediction_probabilities.numpy())[0]
[print((class_name,prob)) 
 for (number,class_name,prob) in predicted_top5]
tensor_to_image(content_image)

hub_module=th.load(tfhub_path)
get_file('06_001.png')
get_file('02_018.png')
content_image=load_img('06_001.png')
style_image=load_img('02_018.png')
stylized_image=hub_module(
    tf.constant(content_image),
    tf.constant(style_image))[0]
tensor_to_image(stylized_image)

# Commented out IPython magic to ensure Python compatibility.
# %decor_header Keras Models

def mlp_model(img_size,num_classes):
    model=tf.keras.models.Sequential([
        tf.keras.layers.Flatten(
            input_shape=(img_size,img_size,3)),
        tf.keras.layers.Dense(128,activation='relu'),
        tf.keras.layers.BatchNormalization(),    
        tf.keras.layers.Dense(256,activation='relu'),
        tf.keras.layers.BatchNormalization(),    
        tf.keras.layers.Dense(512,activation='relu'),
        tf.keras.layers.BatchNormalization(),   
        tf.keras.layers.Dense(1024,activation='relu'),
        tf.keras.layers.Dropout(.2),
        tf.keras.layers.Dense(num_classes,activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

model=mlp_model(128,20)
model.fit(x_train,y_train,epochs=100,batch_size=16,
          callbacks=cb(model_weights),
          validation_data=(x_valid,y_valid));

model.load_weights(model_weights)
model.evaluate(x_test,y_test)

model=mlp_model(32,10)
model.fit(x_train2,y_train2,epochs=100,batch_size=16,
          validation_data=(x_valid2,y_valid2),
          callbacks=cb(model_weights2))

model.load_weights(model_weights2)
model.evaluate(x_test2,y_test2)

def cnn_model(img_size,num_classes):
    model=tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(
            32,(5,5),padding='same',
            input_shape=(img_size,img_size,3)),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.Conv2D(196,(5,5)),
        tf.keras.layers.Activation('relu'),    
        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.GlobalAveragePooling2D(),    
        tf.keras.layers.Dense(512),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.Dense(128),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.Dropout(.25),
        tf.keras.layers.Dense(num_classes,activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

model=cnn_model(128,20)
model.fit(x_train,y_train,epochs=100,batch_size=64,
          validation_data=(x_valid,y_valid),
          callbacks=cb(model_weights))

model.load_weights(model_weights)
model.evaluate(x_test,y_test)

model=cnn_model(32,10)
model.fit(x_train2,y_train2,epochs=100,batch_size=64,
          validation_data=(x_valid2,y_valid2),
          callbacks=cb(model_weights2))

model.load_weights(model_weights2)
model.evaluate(x_test2,y_test2)

def rnn_model(img_size,hidden,num_classes):
    model=tf.keras.models.Sequential([
        tf.keras.layers.BatchNormalization(
            input_shape=(1,3*img_size**2)),
        tf.keras.layers.LSTM(hidden,return_sequences=True),
        tf.keras.layers.LSTM(hidden,return_sequences=True),
        tf.keras.layers.LSTM(hidden),
        tf.keras.layers.BatchNormalization(),     
        tf.keras.layers.Dense(num_classes,activation='softmax')
    ])
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='adam',metrics=['accuracy'])    
    return model

model=rnn_model(128,256,20)
model.fit(x_train.reshape(-1,1,128*128*3),y_train,
          epochs=100,batch_size=128,callbacks=cb(model_weights),
          validation_data=(x_valid.reshape(-1,1,128*128*3),y_valid))

model.load_weights(model_weights)
model.evaluate(x_test.reshape(-1,1,128*128*3),y_test)

model=rnn_model(32,128,10)
model.fit(x_train2.reshape(-1,1,32*32*3),y_train2,
          epochs=50,batch_size=128,callbacks=cb(model_weights2),
          validation_data=(x_valid2.reshape(-1,1,32*32*3),y_valid2))

model.load_weights(model_weights2)
model.evaluate(x_test2.reshape(-1,1,32*32*3),y_test2)