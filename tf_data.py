# -*- coding: utf-8 -*-
"""tf_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m0IooZ52Z1mZ9o0uaOW4pgkFzJw4lH-l
"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.display import display,HTML
def dhtml(str):
    display(HTML("""<style>
    @import 'https://fonts.googleapis.com/css?family=Akronim&effect=3d';      
    </style><h1 class='font-effect-3d' 
    style='font-family:Akronim; color:#ff55ee; font-size:35px;'>
#     %s</h1>"""%str))
def phtml(str):
    display(HTML("""<style>
    @import 'https://fonts.googleapis.com/css?family=Smokum&effect=3d-float';      
    </style><h1 class='font-effect-3d-float' 
    style='font-family:Smokum; color:#9955ee; font-size:25px;'>
#     %s</h1>"""%str))

dhtml('Code Modules & Functions')

import warnings; warnings.filterwarnings('ignore')
import tensorflow as tf,pylab as pl
import pandas as pd,numpy as np,seaborn as sb
import tensorflow.keras.utils as tku
from tensorflow.data import Dataset as tds
import sklearn.model_selection as sms

def pd_style():
    return [dict(selector="th",
                 props=[("font-size","12pt")]),
            dict(selector="td",
                 props=[('padding',"0em 0em")]),
            dict(selector="th:hover",
                 props=[("font-size","14pt")]),
            dict(selector="tr:hover td:hover",
                 props=[('max-width','200px'),
                        ('font-size','12pt')])]

dhtml('Data Processing')

url="http://archive.ics.uci.edu/ml/machine-learning-databases"+\
    "/auto-mpg/auto-mpg.data"
dp=tku.get_file("auto-mpg.data",url)
columns=['MPG','Cylinders','Displacement','Horsepower',
         'Weight','Acceleration','ModelYear','Origin']
numeric_columns=columns[2:6]
df=pd.read_csv(dp,names=columns,
               na_values="?",comment='\t',sep=" ",
               skipinitialspace=True)
df.head(10).style.background_gradient('cool', axis=1)\
    .set_properties(**{'max-width':'80px','font-size':'1pt'})\
    .set_caption(phtml("Data Exploration"))\
    .set_precision(2)\
    .set_table_styles(pd_style())

df=df.dropna().reset_index(drop=True)
df.tail(10).style\
.background_gradient(cmap='cool',axis=0,
                     subset=numeric_columns)

stats=df.describe().transpose()
dfn=df.copy()
for nc in numeric_columns:
    mean=stats.loc[nc,'mean']
    std=stats.loc[nc,'std']
    dfn.loc[:,nc]=(dfn.loc[:,nc]-mean)/std
dfn.tail(10).style\
.bar(align='mid',color=['#ff55ee','#9955ee'],
     subset=numeric_columns)

dhtml('TF Data')

numeric_features=[]
for nc in numeric_columns:
    nf=tf.feature_column.numeric_column(key=nc)
    numeric_features.append(nf) 
for nf in numeric_features: 
    phtml(str(nf)); break

fyear=tf.feature_column.numeric_column(key="ModelYear")
fcylinders=tf.feature_column.numeric_column(key="Cylinders")
bucketized_features=[]
fyear=tf.feature_column.bucketized_column(
    source_column=fyear,boundaries=[73,76,79])
fcylinders=tf.feature_column.bucketized_column(
    source_column=fcylinders,boundaries=[4,6,8])
bucketized_features.append(fyear)
bucketized_features.append(fcylinders)
for bf in bucketized_features: 
    phtml(str(bf)); break

forigin=tf.feature_column\
.categorical_column_with_vocabulary_list(
    key='Origin',vocabulary_list=[1,2,3])
categorical_features=\
[tf.feature_column.indicator_column(forigin)]
phtml(str(categorical_features[0]))

features=(numeric_features+
          bucketized_features+ 
          categorical_features)
dfn_train,dfn_test=\
sms.train_test_split(dfn,train_size=.8,shuffle=True)
len(dfn_train),len(dfn_test)

batch_size=8
def train_input_fn(dfn_train,batch_size):
    dft=dfn_train.copy()
    x_train,y_train=dft,dft.pop('MPG')
    ds_train=tds.from_tensor_slices((dict(x_train),y_train))
    return ds_train.shuffle(1000).repeat().batch(batch_size)
ds_train=train_input_fn(dfn_train,batch_size)
batch=next(iter(ds_train))
phtml('keys: </br>%s'%batch[0].keys())
phtml('batch values of `Cylinders`: </br> %s'%batch[0]['Cylinders'])

def test_input_fn(dfn_test,batch_size):
    dft2=dfn_test.copy()
    x_test,y_test=dft2,dft2.pop('MPG')
    ds_test=tds.from_tensor_slices((dict(x_test),y_test))
    return ds_test.batch(batch_size)
ds_test=train_input_fn(dfn_test,batch_size)
batch=next(iter(ds_test))
phtml('keys: </br>%s'%batch[0].keys())
phtml('batch values of `ModelYear`: </br>%s'%\
      batch[0]['ModelYear'])

dhtml('TF Regressor')

reg=tf.estimator.DNNRegressor(
    feature_columns=features,hidden_units=[32,10],
    model_dir='models/autompg-dnnregressor/');

epochs=1000
steps=epochs*int(np.ceil(len(dfn_train)/batch_size))
phtml('training steps: %d'%steps)
reg.train(input_fn=lambda:\
          train_input_fn(dfn_train,
          batch_size),steps=steps);

reloaded_reg=tf.estimator.DNNRegressor(
    feature_columns=features,hidden_units=[32,10],
    warm_start_from='models/autompg-dnnregressor/',
    model_dir='models/autompg-dnnregressor/')

test_results=reloaded_reg\
.evaluate(input_fn=lambda:\
          test_input_fn(dfn_test,batch_size))
for key in test_results:
    phtml('{}: {}'.format(key,test_results[key]))
phtml('test average loss% {:.4f}'\
      .format(test_results['average_loss']))

y_test_pred=reg.predict(input_fn=lambda:\
                        test_input_fn(dfn_test,batch_size))
py_test=[]
for i in range(len(dfn_test)):
    py_test.append(next(iter(y_test_pred))['predictions'][0])

pl.figure(figsize=(10,4))
pl.plot(range(len(dfn_test)),dfn_test['MPG'],
        '-o',label='real data',c='#9955ee',ms=7)
pl.plot(range(len(dfn_test)),py_test,
        '-o',label='predictions',c='#ff55ee',ms=5)
pl.grid(); pl.legend();