# -*- coding: utf-8 -*-
"""flower_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H2ArWH_1kYfkIoCbxleX-aHAozRVBAdB

# üìë &nbsp; Deep Learning. P0: Image Classification

<a href="https://olgabelitskaya.github.io/README.html">&#x1F300; &nbsp; Home Page &nbsp; &nbsp; &nbsp;</a> 
<a href="https://www.instagram.com/olga.belitskaya/">&#x1F300; &nbsp; Instagram Posts &nbsp; &nbsp; &nbsp;</a>  <a href="https://www.pinterest.ru/olga_belitskaya/code-style/">&#x1F300; &nbsp; Pinterest Posts &nbsp; &nbsp; &nbsp;</a><br/>
In this project, we'll classify images from the 
<a href="https://www.kaggle.com/olgabelitskaya/flower-color-images">Flower Color Images Dataset.</a><br/>
The content is very simple:<br/> 
210 images (128x128x3) with 10 species of flowering plants 
stored in the file <i>FlowerColorImages.h5.zip</i>.<br/>
In the original dataset, photo files are in the .png format and the labels are integers.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%html
# <table style="width:30%; background-color:lightgray; 
#               font-family:'Lobster'; font-size:150%;">
# <tr><th>Label </th><th> Flower Name </th></tr>
# <tr><td style="color:#FF355E;"><center> 0 </center></td>
# <td style="color:#FF355E;"><left> => phlox </left></td></tr>
# <tr><td style="color:#FF6037;"><center> 1 </center></td>
# <td style="color:#FF6037;"><left> => rose </left></td></tr>
# <tr><td style="color:#FF9966;"><center> 2 </center></td>
# <td style="color:#FF9966;"><left> => calendula </left></td></tr>
# <tr><td style="color:#FFCC33;"><center> 3 </center></td>
# <td style="color:#FFCC33;"><left> => iris </left></td></tr> 
# <tr><td style="color:#FFFF66;"><center> 4 </center></td>
# <td style="color:#FFFF66;"><left> => max chrysanthemum </left></td></tr>
# <tr><td style="color:#CCFF00;"><center> 5 </center></td>
# <td style="color:#CCFF00;"><left> => bellflower </left></td></tr>
# <tr><td style="color:#66FF66;"><center> 6 </center></td>
# <td style="color:#66FF66;"><left> => viola </left></td></tr>
# <tr><td style="color:#50BFE6;"><center> 7 </center></td>
# <td style="color:#50BFE6;"><left> => rudbeckia laciniata </left></td></tr>
# <tr><td style="color:#FF6EFF;"><center> 8 </center></td>
# <td style="color:#FF6EFF;"><left> => peony </left></td></tr>
# <tr><td style="color:#FF00CC;"><center> 9 </center></td>
# <td style="color:#FF00CC;"><left> => aquilegia </left></td></tr>
# </table>

"""We'll preprocess the images, then train a neural network on all the samples.<br/> 
The images need to be normalized and the labels need to be one-hot encoded.<br/>
We are going to apply 
<a href="https://keras.io/">Keras: The Python Deep Learning library.</a><br/>
At the end, we'll get to see the neural network's predictions on the sample images.<br/>
## ‚úíÔ∏è &nbsp;Step 0. Import Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

import pandas as pd,numpy as np,pylab as pl
import keras as ks,tensorflow as tf
import zipfile,h5py,urllib,random
import warnings; warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical

from keras.preprocessing import image as ksimage
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint,EarlyStopping
from keras.callbacks import ReduceLROnPlateau
from keras.models import Sequential,load_model
from keras.layers import BatchNormalization,Conv2D,Dense
from keras.layers import LSTM,Flatten,Activation,Dropout
from keras.layers.advanced_activations import PReLU,LeakyReLU
from keras.layers import MaxPooling2D,GlobalMaxPooling2D

from keras import __version__
print('keras version:', __version__)
print('tensorflow version:', tf.__version__)

"""## ‚úíÔ∏è &nbsp;Step 1. Load and Explore the Data"""

path='https://olgabelitskaya.github.io/'
zf='FlowerColorImages.h5.zip'
input_file=urllib.request.urlopen(path+zf)
output_file=open(zf,'wb'); 
output_file.write(input_file.read())
output_file.close(); input_file.close()
zipf=zipfile.ZipFile(zf,'r')
zipf.extractall(''); zipf.close()
f=h5py.File(zf[:-4],'r'); keys=list(f.keys())
images=np.array(f[keys[0]])
labels=np.array(f[keys[1]])
names=['phlox','rose','calendula','iris',
       'max chrysanthemum','bellflower','viola',
       'rudbeckia laciniata','peony','aquilegia']

st1='Images => array shape: %s'
st2='Labels => array shape: %s'
print(st1%str(images.shape))
print(st2%str(labels.shape))
fig=pl.figure(figsize=(12,8))
n=random.randint(1,30)
for i in range(n,n+8):
    ax=fig.add_subplot(2,4,i-n+1,\
    xticks=[],yticks=[],title=names[labels[i]])
    ax.imshow((images[i]/255))
pl.show()

"""## ‚úíÔ∏è &nbsp;Step 2. Save and Load the Data"""

images_csv=images.reshape(210,128*128*3)
np.savetxt("flower_images.csv",images_csv,
           fmt='%i',delimiter=",")
np.savetxt("flower_labels.csv",labels,
           fmt='%i',delimiter=",")
images=pd.read_csv("flower_images.csv",header=None)
labels=pd.read_csv("flower_labels.csv",header=None)
display(images.iloc[:int(10),:int(10)])
display(labels.iloc[:int(20)].T)

"""## ‚úíÔ∏è &nbsp;Step 3. Implement Preprocess Functions"""

images=images.values; labels=labels.values
images=images.reshape(-1,128,128,3)/255
labels=to_categorical(labels,10)

x_train,x_test,y_train,y_test=\
train_test_split(images,labels,test_size=.1,random_state=1)
m=int(len(x_test)/2)
x_valid,y_valid=x_test[:m],y_test[:m]
x_test,y_test=x_test[m:],y_test[m:]
del images,labels
display([x_train.shape,x_test.shape,x_valid.shape,
         y_train.shape,y_test.shape,y_valid.shape])

st='Label: '+names[np.argmax(y_train[n])]
print(st); pl.figure(figsize=(4,3))
pl.imshow((x_train[n])); pl.show()

"""## ‚úíÔ∏è &nbsp;Step 4. Define the Model"""

def model():
    model=Sequential()
    model.add(Conv2D(32,(5,5),padding='same', 
                     input_shape=x_train.shape[1:]))
    model.add(Activation('relu'))    
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(.25))
    model.add(Conv2D(96,(5,5)))
    model.add(Activation('relu'))   
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(.25))
    model.add(GlobalMaxPooling2D())
    
    model.add(Dense(1024,activation='tanh'))
    model.add(Dropout(.25))    
    model.add(Dense(64,activation='tanh'))
    model.add(Dropout(.25)) 
    model.add(Dense(10))
    model.add(Activation('softmax'))

    model.compile(loss='categorical_crossentropy',
                  optimizer='nadam',metrics=['accuracy'])   
    return model
model=model()

"""## ‚úíÔ∏è &nbsp;Step 5. Train the Model"""

fw='weights.best.flowers.hdf5'
early_stopping=EarlyStopping(monitor='val_loss',patience=20,verbose=2)
checkpointer=ModelCheckpoint(filepath=fw,save_best_only=True,verbose=2)
lr_reduction=ReduceLROnPlateau(monitor='val_loss',verbose=2,
                               patience=5,factor=.8)
history=model.fit(x_train,y_train,epochs=100,batch_size=16,
                  verbose=2,validation_data=(x_valid,y_valid),
                  callbacks=[checkpointer,early_stopping,lr_reduction])

def history_plot(fit_history):
    pl.figure(figsize=(12,10)); pl.subplot(211)
    keys=list(fit_history.history.keys())[0:4]
    pl.plot(fit_history.history[keys[0]],
            color='slategray',label='train')
    pl.plot(fit_history.history[keys[2]],
            color='#348ABD',label='valid')
    pl.xlabel("Epochs"); pl.ylabel("Loss")
    pl.legend(); pl.grid()
    pl.title('Loss Function')     
    pl.subplot(212)
    pl.plot(fit_history.history[keys[1]],
            color='slategray',label='train')
    pl.plot(fit_history.history[keys[3]],
            color='#348ABD',label='valid')
    pl.xlabel("Epochs"); pl.ylabel("Accuracy")    
    pl.legend(); pl.grid()
    pl.title('Accuracy'); pl.show()
history_plot(history)

"""## ‚úíÔ∏è &nbsp;Step 6. Evaluate and Save the Model"""

model.load_weights(fw)
model.save('model.h5')
model=load_model('model.h5')
model.evaluate(x_test,y_test)

"""## ‚úíÔ∏è &nbsp;Step 7. Display Predictions"""

y_test_predict=model.predict_classes(x_test)
fig=pl.figure(figsize=(12,6))
randch=np.random.choice(x_test.shape[0],size=10,replace=False)
for i,idx in enumerate(randch):
    ax=fig.add_subplot(2,5,i+1,xticks=[],yticks=[])
    ax.imshow(np.squeeze(x_test[idx]))
    pred_idx=y_test_predict[idx]
    true_idx=np.argmax(y_test[idx])
    ax.set_title("{} ({})".format(names[pred_idx],names[true_idx]),
                 color=("#4876ff" if pred_idx==true_idx else "darkred"))
pl.show()

"""## ‚úíÔ∏è &nbsp; Step 8. Keras Applications"""

from keras.applications.vgg16 \
import VGG16,preprocess_input as prei16
from keras.preprocessing import image as ksimage
from keras.models import Model
from keras.layers import Dense,GlobalAveragePooling2D
from keras.layers.advanced_activations import LeakyReLU

vgg16bmodel=VGG16(weights='imagenet',include_top=False)
pvx_train=vgg16bmodel.predict(x_train)
pvx_valid=vgg16bmodel.predict(x_valid)
pvx_test=vgg16bmodel.predict(x_test)
sh=pvx_train.shape[1:]

def vgg16model():
    model=Sequential()  
    model.add(GlobalAveragePooling2D(input_shape=sh))   
    model.add(Dense(512))
    model.add(LeakyReLU(alpha=.02))
    model.add(Dropout(.5))        
    model.add(Dense(64))
    model.add(LeakyReLU(alpha=.02))
    model.add(Dropout(.25))   
    model.add(Dense(10,activation='softmax'))    
    model.compile(loss='categorical_crossentropy',
                  optimizer='nadam',metrics=['accuracy'])
    return model
vgg16model=vgg16model()

checkpointer=ModelCheckpoint(filepath=fw,verbose=2,save_best_only=True)
lr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,
                               verbose=2,factor=.8)
estopping=EarlyStopping(monitor='val_loss',patience=30,verbose=2)
history=vgg16model.fit(pvx_train,y_train, 
                       validation_data=(pvx_valid,y_valid), 
                       epochs=800,batch_size=64,verbose=2, 
                       callbacks=[checkpointer,lr_reduction,estopping])

history_plot(history)
vgg16model.load_weights(fw)
vgg16model.evaluate(pvx_test,y_test)

from keras.applications.inception_v3 \
import InceptionV3,preprocess_input as iv3pi
iv3bmodel=InceptionV3(weights='imagenet',include_top=False)
x=iv3bmodel.output
x=GlobalAveragePooling2D()(x)
x=Dense(512)(x)
x=LeakyReLU(alpha=.02)(x)
y=Dense(10,activation='softmax')(x)
iv3model=Model(inputs=iv3bmodel.input,outputs=y)
for layer in iv3bmodel.layers:
    layer.trainable=False    
iv3model.compile(optimizer='adam',
                 loss='categorical_crossentropy',
                 metrics=['accuracy'])

steps,epochs=189,10
generator=ksimage.ImageDataGenerator(shear_range=.2,zoom_range=.2,
                                     horizontal_flip=True)
checkpointer=ModelCheckpoint(filepath=fw,verbose=2,save_best_only=True)
lr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,
                               verbose=2,factor=.8)
history=iv3model.fit_generator(generator.flow(x_train,y_train,batch_size=64), 
                               steps_per_epoch=steps,epochs=epochs, 
                               callbacks=[checkpointer,lr_reduction],
                               validation_data=(x_valid,y_valid))

for i,layer in enumerate(iv3bmodel.layers[173:]):
    print(i,layer.name)

for layer in iv3model.layers[:173]:
    layer.trainable=False
for layer in iv3model.layers[173:]:
    layer.trainable=True
iv3model.compile(optimizer='adam',
                 loss='categorical_crossentropy',
                 metrics=['accuracy'])
history=iv3model.\
fit_generator(generator.flow(x_train,y_train,batch_size=64), 
                             steps_per_epoch=steps,epochs=epochs, 
                             callbacks=[checkpointer,lr_reduction],
                             validation_data=(x_valid,y_valid))

iv3model.load_weights(fw)
scores=iv3model.evaluate(x_test,y_test)
print("Accuracy: %.2f%%"%(scores[1]*100))

y_test_predict=iv3model.predict(x_test)
y_test_predict=[np.argmax(y_test_predict[i]) for i in range(11)]
y_test_predict

fig=pl.figure(figsize=(12,4))
randch=np.random.choice(x_test.shape[0],size=5,replace=False)
for i,idx in enumerate(randch):
    ax=fig.add_subplot(1,5,i+1,xticks=[],yticks=[])
    ax.imshow(np.squeeze(x_test[idx]))
    pred_idx=y_test_predict[idx]
    true_idx=np.argmax(y_test[idx])
    ax.set_title("{} ({})".format(names[pred_idx],names[true_idx]),
                 color=("#4876ff" if pred_idx==true_idx else "darkred"))
pl.show()