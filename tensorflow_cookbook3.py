# -*- coding: utf-8 -*-
"""tensorflow_cookbook3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UXD9nxTS9s2EGkiRst59NREqX9Eiw3Zp
"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.display import display,HTML
def dhtml(str):
    display(HTML("""<style>
    @import url('https://fonts.googleapis.com/css?family=Ewert&effect=3d');      
    </style><h1 class='font-effect-3d' style='font-family:Ewert; color:#ff355e'>
#     %s</h1>"""%str))

dhtml('Code Modules & Helpful Functions')

import numpy as np,pylab as pl,pandas as pd
import sys,h5py,urllib,zipfile
import tensorflow as tf
import tensorflow_hub as th
from sklearn.model_selection import train_test_split

fpath='https://olgabelitskaya.github.io/'
fw='weights.best.hdf5'
def prepro(x_train,y_train,x_test,y_test,n_class):
    n=int(len(x_test)/2)    
    x_valid,y_valid=x_test[:n],y_test[:n]
    x_test,y_test=x_test[n:],y_test[n:]
    cy_train=tf.keras.utils.to_categorical(y_train,n_class) 
    cy_valid=tf.keras.utils.to_categorical(y_valid,n_class)
    cy_test=tf.keras.utils.to_categorical(y_test,n_class)
    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],
                     [y_train.shape,y_valid.shape,y_test.shape],
                     [cy_train.shape,cy_valid.shape,cy_test.shape]],
                    columns=['train','valid','test'],
                    index=['images','labels','encoded labels'])
    display(df)
    return [[x_train,x_valid,x_test],
            [y_train,y_valid,y_test],
            [cy_train,cy_valid,cy_test]]
def cb(fw):
    early_stopping=tf.keras.callbacks\
    .EarlyStopping(monitor='val_loss',patience=20,verbose=2)
    checkpointer=tf.keras.callbacks\
    .ModelCheckpoint(filepath=fw,save_best_only=True,verbose=2)
    lr_reduction=tf.keras.callbacks\
    .ReduceLROnPlateau(monitor='val_loss',verbose=2,
                       patience=5,factor=.8)
    return [checkpointer,early_stopping,lr_reduction]
def display_resize(x_train,x_valid,x_test,
                   y_valid,cy_valid,pixels):
    x_train=tf.image.resize(x_train,[pixels,pixels])
    x_valid=tf.image.resize(x_valid,[pixels,pixels])
    x_test=tf.image.resize(x_test,[pixels,pixels])
    img=x_valid[1]
    lbl='one example of resized images \nlabel: '+\
     str(y_valid[1][0])+'=>'+str(cy_valid[1])+\
     '\nshape: '+str(img.shape)
    pl.imshow(img); pl.title(lbl)
    return [x_train,x_valid,x_test]

def premodel(pixels,dense,mh,labels):
    model=tf.keras.Sequential([
        tf.keras.layers.Input((pixels,pixels,3),
                              name='input'),
        th.KerasLayer(mh,trainable=True),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(dense,activation='relu'),
        tf.keras.layers.Dropout(rate=.5),
        tf.keras.layers.Dense(labels,activation='softmax')])
    model.compile(optimizer='adam',metrics=['accuracy'],
                  loss='categorical_crossentropy')
    display(model.summary())
    return model

dhtml('Data Loading & Preprocessing')

zf='DecorColorImages.h5.zip'
input_file=urllib.request.urlopen(fpath+zf)
output_file=open(zf,'wb'); 
output_file.write(input_file.read())
output_file.close(); input_file.close()
zipf=zipfile.ZipFile(zf,'r')
zipf.extractall(''); zipf.close()
f=h5py.File(zf[:-4],'r')
keys=list(f.keys()); print(keys)
images=np.array(f[keys[2]])/255
labels=np.array(f[keys[1]]).astype('int').reshape(-1,1)-1
x_train1,x_test1,y_train1,y_test1=\
train_test_split(images,labels,test_size=.2,random_state=1)
del images,labels
[[x_train1,x_valid1,x_test1],
 [y_train1,y_valid1,y_test1],
 [cy_train1,cy_valid1,cy_test1]]=\
prepro(x_train1,y_train1,x_test1,y_test1,7)

(x_train2,y_train2),(x_test2,y_test2)=\
tf.keras.datasets.cifar10.load_data()
[[x_train2,x_valid2,x_test2],
 [y_train2,y_valid2,y_test2],
 [cy_train2,cy_valid2,cy_test2]]=\
prepro(x_train2/255,y_train2,x_test2/255,y_test2,10)

zf='LetterColorImages_123.h5.zip'
input_file=urllib.request.urlopen(fpath+zf)
output_file=open(zf,'wb'); 
output_file.write(input_file.read())
output_file.close(); input_file.close()
zipf=zipfile.ZipFile(zf,'r')
zipf.extractall(''); zipf.close()
f=h5py.File(zf[:-4],'r')
keys=list(f.keys()); print(keys)
images=np.array(f[keys[1]])/255
labels=np.array(f[keys[2]]).astype('int').reshape(-1,1)-1
x_train3,x_test3,y_train3,y_test3=\
train_test_split(images,labels,test_size=.2,random_state=1)
del images,labels
[[x_train3,x_valid3,x_test3],
 [y_train3,y_valid3,y_test3],
 [cy_train3,cy_valid3,cy_test3]]=\
prepro(x_train3,y_train3,x_test3,y_test3,33)

zf='FlowerColorImages.h5.zip'
input_file=urllib.request.urlopen(fpath+zf)
output_file=open(zf,'wb'); 
output_file.write(input_file.read())
output_file.close(); input_file.close()
zipf=zipfile.ZipFile(zf,'r')
zipf.extractall(''); zipf.close()
f=h5py.File(zf[:-4],'r')
keys=list(f.keys())
images=np.array(f[keys[0]])/255
labels=np.array(f[keys[1]]).astype('int').reshape(-1,1)
x_train4,x_test4,y_train4,y_test4=\
train_test_split(images,labels,test_size=.2,random_state=1)
del images,labels
[[x_train4,x_valid4,x_test4],
 [y_train4,y_valid4,y_test4],
 [cy_train4,cy_valid4,cy_test4]]=\
prepro(x_train4,y_train4,x_test4,y_test4,10)

dhtml('Pre-Trained Saved Models')

dhtml('#1')
[handle_base,pixels]=["mobilenet_v2_100_192",192]
mhandle="https://tfhub.dev/google/imagenet/{}/feature_vector/4"\
.format(handle_base)

[x_train1,x_valid1,x_test1]=\
display_resize(x_train1,x_valid1,x_test1,
               y_valid1,cy_valid1,pixels)

model=premodel(pixels,1024,mhandle,7)

history=model.fit(x=x_train1,y=cy_train1,batch_size=16,
                  epochs=50,callbacks=cb(fw),
                  validation_data=(x_valid1,cy_valid1))

model.load_weights(fw)
model.evaluate(x_test1,cy_test1)

[handle_base,pixels]=["mobilenet_v2_140_224",224]
mhandle="https://tfhub.dev/google/imagenet/{}/feature_vector/4"\
.format(handle_base)

[x_train1,x_valid1,x_test1]=\
display_resize(x_train1,x_valid1,x_test1,
               y_valid1,cy_valid1,pixels)

model=premodel(pixels,1024,mhandle,7)

history=model.fit(x=x_train1,y=cy_train1,batch_size=16,
                  epochs=50,callbacks=cb(fw),
                  validation_data=(x_valid1,cy_valid1))

model.load_weights(fw)
model.evaluate(x_test1,cy_test1)
del x_train1,x_valid1,x_test1,\
y_train1,y_valid1,y_test1,\
cy_train1,cy_valid1,cy_test1

dhtml('#2')
[handle_base,pixels]=["mobilenet_v2_050_96",96]
mhandle="https://tfhub.dev/google/imagenet/{}/feature_vector/4"\
.format(handle_base)

[x_train2,x_valid2,x_test2]=\
display_resize(x_train2,x_valid2,x_test2,
               y_valid2,cy_valid2,pixels)

model=premodel(pixels,512,mhandle,10)

history=model.fit(x=x_train2,y=cy_train2,batch_size=64,
                  epochs=10,callbacks=cb(fw),
                  validation_data=(x_valid2,cy_valid2))

model.load_weights(fw)
model.evaluate(x_test2,cy_test2)

[handle_base,pixels]=["mobilenet_v2_075_96",96]
mhandle="https://tfhub.dev/google/imagenet/{}/feature_vector/4"\
.format(handle_base)

model=premodel(pixels,1024,mhandle,10)

history=model.fit(x=x_train2,y=cy_train2,batch_size=64,
                  epochs=10,callbacks=cb(fw),
                  validation_data=(x_valid2,cy_valid2))

model.load_weights(fw)
model.evaluate(x_test2,cy_test2)
del x_train2,x_valid2,x_test2,\
y_train2,y_valid2,y_test2,\
cy_train2,cy_valid2,cy_test2

dhtml('#3')
[handle_base,pixels]=["mobilenet_v2_050_96",96]
mhandle="https://tfhub.dev/google/imagenet/{}/feature_vector/4"\
.format(handle_base)

[x_train3,x_valid3,x_test3]=\
display_resize(x_train3,x_valid3,x_test3,
               y_valid3,cy_valid3,pixels)

model=premodel(pixels,512,mhandle,33)

history=model.fit(x=x_train3,y=cy_train3,batch_size=64,
                  epochs=50,callbacks=cb(fw),
                  validation_data=(x_valid3,cy_valid3))

model.load_weights(fw)
model.evaluate(x_test3,cy_test3)
del x_train3,x_valid3,x_test3,\
y_train3,y_valid3,y_test3,\
cy_train3,cy_valid3,cy_test3

dhtml('#4')
[handle_base,pixels]=["mobilenet_v1_100_128",128]
mhandle="https://tfhub.dev/google/imagenet/{}/feature_vector/4"\
.format(handle_base)

model=premodel(pixels,512,mhandle,10)

history=model.fit(x=x_train4,y=cy_train4,batch_size=8,
                  epochs=50,callbacks=cb(fw),
                  validation_data=(x_valid4,cy_valid4))

model.load_weights(fw)
model.evaluate(x_test4,cy_test4)

[handle_base,pixels]=["mobilenet_v2_130_224",224]
mhandle="https://tfhub.dev/google/imagenet/{}/feature_vector/4"\
.format(handle_base)

[x_train4,x_valid4,x_test4]=\
display_resize(x_train4,x_valid4,x_test4,
               y_valid4,cy_valid4,pixels)

model=premodel(pixels,512,mhandle,10)

history=model.fit(x=x_train4,y=cy_train4,batch_size=8,
                  epochs=50,callbacks=cb(fw),
                  validation_data=(x_valid4,cy_valid4))

model.load_weights(fw)
model.evaluate(x_test4,cy_test4)