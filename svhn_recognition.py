# -*- coding: utf-8 -*-
"""svhn_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QYQNGNxp3-L_u_IPsvxPZ9vZBtrQ4PSD

# SVHN Recognition
The Dataset: http://ufldl.stanford.edu/housenumbers/
"""

!pip install -U -q PyDrive
!pip install -q keras

import warnings
warnings.filterwarnings('ignore')

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from google.colab import files
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

import pandas
import numpy

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pylab as plt
from matplotlib import cm
# %matplotlib inline

from keras.models import Sequential, Model
from keras.optimizers import SGD, RMSprop, Adam, Nadam
from keras.callbacks import ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical

from keras.layers import Dense, Dropout, LSTM
from keras.layers import Activation, Flatten, Input, BatchNormalization
from keras.layers import Conv1D, MaxPooling1D 
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D

from keras import __version__
print('keras version:', __version__)

!ls

"""# Load & Explore the Data"""

project_id = 'nodal-bison-150504'
bucket_name = 'symbol_classification_sets'

!gsutil cp gs://{bucket_name}/svhn_train_images2.csv /tmp/svhn_train_images2.csv

!gsutil cp gs://{bucket_name}/svhn_extra_images2.csv /tmp/svhn_extra_images2.csv

!gsutil cp gs://{bucket_name}/svhn_test_images2.csv /tmp/svhn_test_images2.csv

!gsutil cp gs://{bucket_name}/svhn_train_labels.csv /tmp/svhn_train_labels.csv

!gsutil cp gs://{bucket_name}/svhn_extra_labels.csv /tmp/svhn_extra_labels.csv

!gsutil cp gs://{bucket_name}/svhn_test_labels.csv /tmp/svhn_test_labels.csv

train_images = pandas.read_csv('/tmp/svhn_train_images2.csv')
train_labels = pandas.read_csv('/tmp/svhn_train_labels.csv')

test_images = pandas.read_csv('/tmp/svhn_test_images2.csv')
test_labels = pandas.read_csv('/tmp/svhn_test_labels.csv')

extra_images = pandas.read_csv('/tmp/svhn_extra_images2.csv')
extra_labels = pandas.read_csv('/tmp/svhn_extra_labels.csv')

test_images.ix[:10,:10]

test_labels.ix[:10,:]

train_images = train_images.ix[:,1:].as_matrix().astype('float32')
train_labels = train_labels.ix[:,1:].as_matrix().astype('int16')

test_images = test_images.ix[:,1:].as_matrix().astype('float32')
test_labels = test_labels.ix[:,1:].as_matrix().astype('int16')

extra_images = extra_images.ix[:,1:].as_matrix().astype('float32')
extra_labels = extra_labels.ix[:,1:].as_matrix().astype('int16')

print('Label: ', extra_labels[100])
plt.imshow(extra_images[100].reshape(32,32), cmap=plt.cm.bone);

def digit_to_categorical(data):
    n = data.shape[1]
    data_cat = numpy.empty([len(data), n, 11])    
    for i in range(n):
        data_cat[:, i] = to_categorical(data[:, i], num_classes=11)        
    return data_cat

x_train = numpy.concatenate((train_images.reshape(-1, 32, 32, 1),
                             test_images.reshape(-1, 32, 32, 1)),
                            axis=0)
y_train = numpy.concatenate((digit_to_categorical(train_labels),
                             digit_to_categorical(test_labels)),
                            axis=0)

x_valid = extra_images.reshape(-1, 32, 32, 1)
y_valid = digit_to_categorical(extra_labels)

n = int(len(x_valid)/2)
x_test, y_test = x_valid[:n], y_valid[:n]
x_valid, y_valid = x_valid[n:], y_valid[n:]

x_train.shape, x_test.shape, x_valid.shape, \
y_train.shape, y_test.shape, y_valid.shape

y_train_list = [y_train[:, i] for i in range(5)]
y_test_list = [y_test[:, i] for i in range(5)]
y_valid_list = [y_valid[:, i] for i in range(5)]

"""# Build the Model"""

def cnn_model():    
    model_input = Input(shape=(32, 32, 1))
    x = BatchNormalization()(model_input)
        
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(model_input)
    x = MaxPooling2D(pool_size=(2, 2))(x) 
    
    x = Conv2D(32, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)    
    x = Dropout(0.25)(x)
    
    x = Conv2D(64, (3, 3), activation='relu')(x)       
    x = Conv2D(64, (3, 3), activation='relu')(x)    
    x = Dropout(0.25)(x)
    
    x = Conv2D(128, (3, 3), activation='relu')(x)    
    x = Dropout(0.25)(x)
              
    x = Flatten()(x)
    
    x = Dense(512, activation='relu')(x)    
    x = Dropout(0.5)(x)
    
    y1 = Dense(11, activation='softmax')(x)
    y2 = Dense(11, activation='softmax')(x)
    y3 = Dense(11, activation='softmax')(x)
    y4 = Dense(11, activation='softmax')(x)
    y5 = Dense(11, activation='softmax')(x)
    
    model = Model(input=model_input, output=[y1, y2, y3, y4, y5])

    model.compile(loss='categorical_crossentropy', 
                  optimizer='nadam', 
                  metrics=['accuracy'])
    return model

cnn_model = cnn_model()
cnn_checkpointer = ModelCheckpoint(filepath='weights.best.svhn.cnn.hdf5', 
                                   verbose=2, save_best_only=True)

cnn_history = cnn_model.fit(x_train, y_train_list, 
                            validation_data=(x_valid, y_valid_list), 
                            epochs=100, batch_size=128, verbose=0, 
                            callbacks=[cnn_checkpointer])

cnn_model.load_weights('weights.best.svhn.cnn.hdf5')
cnn_scores = cnn_model.evaluate(x_test, y_test_list, verbose=0)

print("CNN Model. \n")
print("Scores: \n" , (cnn_scores))
print("First digit. Accuracy: %.2f%%" % (cnn_scores[6]*100))
print("Second digit. Accuracy: %.2f%%" % (cnn_scores[7]*100))
print("Third digit. Accuracy: %.2f%%" % (cnn_scores[8]*100))
print("Fourth digit. Accuracy: %.2f%%" % (cnn_scores[9]*100))
print("Fifth digit. Accuracy: %.2f%%" % (cnn_scores[10]*100))

print(cnn_model.summary())

plt.figure(figsize=(18, 6))

plt.plot(cnn_history.history['val_dense_2_acc'], label = 'First Digit')
plt.plot(cnn_history.history['val_dense_3_acc'], label = 'Second Digit')
plt.plot(cnn_history.history['val_dense_4_acc'], label = 'Third Digit')
plt.plot(cnn_history.history['val_dense_5_acc'], label = 'Fourth Digit')
plt.plot(cnn_history.history['val_dense_6_acc'], label = 'Fifth Digit')

plt.legend()
plt.title('Accuracy');

avg_accuracy = sum([cnn_scores[i] for i in range(6, 11)])/5
print("CNN Model. Average Accuracy: %.2f%%" % (avg_accuracy*100))